#!/usr/bin/env python
# coding: utf-8

# The dataset for this competition is a subset of NIH dataset. 
# 
# It might be useful to use labels provided by NIH to train the model.
# 
# I share the list which associates train images to original NIH images so that you can make use of NIH labels. The list is obtrained by calculating the diffs among images.

# ## Update
# 
# As there is a request to add this for stage1 test images, I've uploaded a new csv 'nih_for_test1_images.csv'.
# 
# - nih.csv: for train images
# - nih_for_test1_images.csv: for stage1 test images
# 
# On this competition, you may use NIH label for training your model, but I not sure you can use NIH label for testing. Please check the disussion about external data https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/discussion/64345

# ## NIH dataset
# 
# Link to the dataset: https://nihcc.app.box.com/v/ChestXray-NIHCC
# 
# NIH labels: https://nihcc.app.box.com/v/ChestXray-NIHCC/file/219760887468

# ## Dataframe to associate patientId to original NIH image and its label

# I calculated the pixel diffs between competition's dataset images and NIH images. A image pair with the minimum diff is treated as the same image. 
# 
# I manually checked hundreds of image pairs and they were all correct.
# 
# After finding out the original NIH images, I put all labels of this competition and NIH into the dataframe, nih.csv.

# #### for train images

# In[ ]:


import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

df = pd.read_csv('../input/nihcsv/nih.csv')
print(df.shape)
df.head(10)
# class2 is the label given in NIH dataset (and imageIndex is filename of the image)


# #### for stage1 test images

# In[ ]:


import os
print(os.listdir('../input/nihcsv'))

test = pd.read_csv('../input/nihcsv/nih_for_test1_images.csv')
print(test.shape)
test.head(10)


# ## NIH label for 'Normal' class
# 
# There are some images labeled 'Nodule' or 'Atelectasis' at NIH but labeled as 'Normal' in this competition. I'm a bit surprised to know there are lots of images with Infiltration at NIH but treated at 'Normal' here.

# In[ ]:


df[df.class1 == 'Normal'].class2.value_counts().to_frame().head(10).plot.bar()


# ## NIH label for 'Lung Opacity' class
# 
# I was expecting most images are labeled as 'Infiltration' at NIH and that was somewhat correct.

# In[ ]:


df[df.class1 == 'Lung Opacity'].class2.value_counts().to_frame().head(10).plot.bar()


# ## NIH label for 'No Lung Opacity / Not Normal' class
# 
# A bit surprising to know there are many images labeled as 'No Finding' at NIH.

# In[ ]:


df[df.class1 == 'No Lung Opacity / Not Normal'].class2.value_counts().to_frame().head(10).plot.bar()


# ## Guessing a reason for label inconsistency between this competition and NIH.
# 
# I'm not a specialist in this field and I can not say much about the variance among specialists's decisions.
# 
# I guess one of the reason is the fact how NIH label is created. https://arxiv.org/pdf/1705.02315.pdf
# NIH label is generated by NLP technique and it might not be as solid as the label in this competition.
# 

# In[ ]:


for class2, count2 in df.class2.value_counts().items():

    if count2 < 100: # ignore small count
        continue

    print('\n----- %s -----' % class2)

    _df = df[df.class2 == class2].class1
    for class1, count1 in _df.value_counts().items():
        ratio = count1 / _df.count()
        print('%d (%.2f%%) %s' % (count1, ratio * 100, class1))

