#!/usr/bin/env python
# coding: utf-8

# In[ ]:


get_ipython().system('pip install git+https://github.com/goolig/dsClass.git')


# In[ ]:


from sklearn.metrics import roc_curve, auc # model performance metrics
import matplotlib.pyplot as plt # plotting
import numpy as np # linear algebra
import os # accessing directory structure
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
from dsClass.path_helper import *


# There is 1 csv file in the current version of the dataset:
# 

# In[ ]:


#print(os.listdir('../input'))


# ### Let's check 1st file: ../input/frd_sample.csv

# In[ ]:


data_path = get_file_path('frd_sample.csv')
df = pd.read_csv(data_path, delimiter=',')
df.dataframeName = 'frd_sample.csv'
nRow, nCol = df.shape
print(f'There are {nRow} rows and {nCol} columns')


# Let's take a quick look at what the data looks like:

# In[ ]:


df.head(5)


# In[ ]:


df.info()


# Let's do some preprocessing:

# In[ ]:


# step1 - encode target variable

d = {"F":1, "G":0}
df["IS_FRAUD"].replace(d, inplace=True)

df.head()


# In[ ]:


# now lets see how bayes works on a simple example of USER_COUNTRY column

df_exp = df[["EVENT_ID", "USER_COUNTRY","IS_FRAUD"]]

df_exp.head()


# In[ ]:


df_exp_train = df_exp.query("EVENT_ID <= 2200")
df_exp_train.tail()


# In[ ]:


df_exp_test  = df_exp.query("EVENT_ID  > 2200")
df_exp_test.tail()


# In[ ]:


tot_frd = df_exp_train.loc[(df_exp_train.IS_FRAUD == 1)].shape[0] # total fraud
tot_gen = df_exp_train.shape[0] - tot_frd

print([tot_frd,tot_gen])


# In[ ]:


countries = df["USER_COUNTRY"].unique()
print(countries)


# In[ ]:


# for each country we calculate likelihood of a transaction being fraudulent

p_f_ctry = {}

for country in countries:
    df_ctry = df_exp_train.loc[(df_exp_train.USER_COUNTRY == country)]
    df_ctry_frd = df_ctry.loc[(df_ctry.IS_FRAUD == 1)]
    
    ctry_frd = df_ctry_frd.shape[0]
    ctry_gen = df_ctry.shape[0] - ctry_frd
    
    if ctry_gen == 0:
        p_f_ctry[country] = 0
    else:
        p_f_ctry[country] = 1000*np.log ( (ctry_frd/tot_frd) / (ctry_gen/tot_gen) )
    
print(p_f_ctry)


# In[ ]:


y_score = df_exp_test["USER_COUNTRY"]
y_score.replace(p_f_ctry, inplace=True)

y_score.head()


# In[ ]:


y_test = df_exp_test["IS_FRAUD"]

y_test.head()


# In[ ]:


# Compute ROC curve and ROC area
    
fpr, tpr, _ = roc_curve(y_test, y_score)
roc_auc = auc(fpr, tpr)

plt.figure()
lw = 1
plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='-')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()


# **Self-Assessment A**
# * Calculate a similar ROC/AUC performance metric on training data and compare it with the above. Would you expect the AUC results to be better/worse than for the testing set?

# In[ ]:


# add code here


# In[ ]:


# Let's generate more features:

# 1. USER_COUNTRY/PAYEE_COUNTRY

df_temp = df.copy()

df_temp["USER_CTRY_PAYEE_CTRY"] = df_temp["USER_COUNTRY"].str.cat(df_temp["PAYEE_COUNTRY"], sep=';')

df_temp.head()


# In[ ]:


# 2. USER_HITS

users = df_temp["USER_ID"].unique()

evt_val_dict = {}
for user in users:
    df_loop = df_temp.loc[(df_temp.USER_ID == user)]
    
    hits = 1
    for index, row in df_loop.iterrows():
        evt_val_dict[row['EVENT_ID']] = hits
        hits = hits + 1
    
df_temp["USER_HITS"] = df_temp["EVENT_ID"].apply(evt_val_dict.get)
df_temp.tail()


# In[ ]:


print(df_temp.query("USER_ID == 'user21'"))


# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# **Self-Assessment B**
# * Using both techniques shown above calculate USER_PAYEE_HITS - number of hits from USER_ID/PAYEE_ID combination
# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------

# In[ ]:


# add code here


# In[ ]:


print(df_temp.query("USER_PAYEE== 'user647;payee2'"))


# In[ ]:


features = ["CHANNEL","ISP","USER_COUNTRY","PAYEE_COUNTRY","USER_CTRY_PAYEE_CTRY","USER_HITS","USER_PAYEE_HITS","IS_FRAUD","EVENT_ID"]

df2 = df_temp[features]
df2.head()


# In[ ]:


df_exp_train = df2.query("EVENT_ID <= 2200")
df_exp_test  = df2.query("EVENT_ID  > 2200")

for feature in features:
    
    if feature == "IS_FRAUD" or feature == "EVENT_ID":
        continue
    
    
    unique_values = df2[feature].unique()
    d = {}
    
    for val in unique_values:
        df_feat = df_exp_train.loc[(df_exp_train[feature] == val)]
        df_feat_frd = df_feat.loc[(df_feat.IS_FRAUD == 1)]

        feat_frd = df_feat_frd.shape[0]
        feat_gen = df_feat.shape[0] - feat_frd
        
        if feat_gen == 0:
            d[val] = 0
        else:
            d[val] = 1000*np.log ( (feat_frd/tot_frd) / (feat_gen/tot_gen) )
    
    df_exp_test[feature].replace(d, inplace=True)
    df_exp_train[feature].replace(d, inplace=True)

df_exp_test.tail()


# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# **Self-Assessment C**
# 
# Note "-inf" values for some columns, why this is happening and how we can fix it?
# 
# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------

# In[ ]:


# add code here


# In[ ]:


df_exp_train.info()


# In[ ]:


# now we aggregate the contribution of different features into a single fraud likelihood

df_exp_train["SCORE"] = 0.0
df_exp_test ["SCORE"] = 0.0

for feature in features:
    
    if feature == "IS_FRAUD" or feature == "EVENT_ID":
        continue
    
    df_exp_train["SCORE"] = df_exp_train["SCORE"] + df_exp_train[feature]
    df_exp_test ["SCORE"] = df_exp_test ["SCORE"] + df_exp_test [feature]
    
df_exp_test.head()


# In[ ]:


y = df_exp_train["IS_FRAUD"]
y_score = df_exp_train["SCORE"]

# Compute ROC curve and ROC area
    
fpr, tpr, _ = roc_curve(y, y_score)
roc_auc = auc(fpr, tpr)

plt.figure()
lw = 1
plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='-')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()


# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# **Self-Assessment D**
# * Is NB classifier suggested above is a black-box or a white-box model. 
# * Suggest and implement a method for feature importance calculation based on df_exp_train data. Plot the importance and discuss the results
# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------

# In[ ]:


# add code here


# Q1

# In[ ]:





# Q2

# 

# Q3

# In[ ]:





# Q4

# In[ ]:




