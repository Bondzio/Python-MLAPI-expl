#!/usr/bin/env python
# coding: utf-8

# In[ ]:





# # Initial Analyais of Titanic Data
# #### In this notebook we will have a look at the datasets provided by Kaggle's Titanic competition. I have tried to add as many comments as possible to explain what the code is doing and why. This notebook is aimed at people just starting out with ML.

# #### This first section is where all libraries to be used are loaded:

# In[ ]:


# Load libraries

get_ipython().run_line_magic('matplotlib', 'inline')

import os                            # Operating system
import numpy as np                   # Linear algebra
import pandas as pd                  # Data processing, CSV file I/O (e.g. pd.read_csv)
pd.plotting.register_matplotlib_converters()
import matplotlib.pyplot as plt      # Data visualisations
import seaborn as sns                # Data visualisations

sns.set(style='white')



# #### Next the list of files in the source data folder is shown:

# In[ ]:


# Get available file names from source folder
for dirname, _, filenames in os.walk("./Source Data/"):
    for filename in filenames:
        print(os.path.join(dirname, filename))


# #### Next the training and testing datasets are loaded into dataframes and each dataframe's shape is shown
#  - The training data here is labelled which means that is contains an extra column indicating the outcome that is to be predicted.
#  - The test data is not labelled because it will be used to generate the predictions to submit to the competition.
#  - The "shape" of a dataframe is basically the number of rows and columns.

# In[ ]:


# Read training and test data
train_data = pd.read_csv('/kaggle/input/titanic/train.csv')
test_data = pd.read_csv('/kaggle/input/titanic/test.csv')

# Check the number of rows and columns in the data
train_data.shape, test_data.shape


# #### Let's have a look at the data types of each column:

# In[ ]:


# Show data types of each column
train_data.dtypes


# #### Sample returns a number of randomly selected rows so we can see what the data looks like:

# In[ ]:


# Show a sample of random rows
train_data.sample(5)


# #### Describe shows a summary of all numeric data columns. Useful measures include:
# - The count shows if there are missing values
# - The mean shows the average value
# - The min and max values show the value range

# In[ ]:


# Show a summary of the numeric columns in the training data
train_data.describe()


# In[ ]:


# Show a summary of the numeric columns in the test data
test_data.describe()


# #### We need to check if any non-numeric columns also have missing values
# - This can be done by defining a function to check all columns in a dataframe
# - Functions are uselful because they allow you to reuse your code

# In[ ]:


# Define a function to check for missing values
def get_missing_summary(dataframe):
    '''Return the count and percentage of missing values in a dataframe'''
    for col in dataframe.columns:
        num_of_missing = dataframe[col].isna().sum()
        perc_of_missing = (dataframe[col].isna().sum() / len(dataframe[col])) * 100
        print('%s  --  %d missing  --  %.1f%%' % (col, num_of_missing, perc_of_missing))


# #### We will pass the function the training and test datesets to check for missing values:

# In[ ]:


# Check training data for any null / missing values
get_missing_summary(train_data)


# In[ ]:


# Check test data for any null / missing values
get_missing_summary(test_data)


# We can see that there is data missing in a few of the columns for both data sets. One column in particular, is missing well over half of its values so we'll probably exclude it as a feature. The missing values for the other columns will have to be imputed (generated by inference)

# #### Next we'll have a closer look at the data
# - Identify the label column
# - Analyse the other columns

# In[ ]:


# Select the name of the label column
label_col = 'Survived'


# In[ ]:


# Plot Pclass values
plt.figure(figsize=(14,4))
plt.title('Number of survivals by Pclass')
sns.countplot(x='Pclass', hue=label_col, data=train_data)


# We can see that more than half the people in 1st class survived, whereas the vast majority of the people in 3rd class died.

# In[ ]:


#Inspect Name values
train_data[['Name', 'Pclass', 'Fare', 'Survived']].sample(20)


# The name column can probably be used to extract the passenger's title

# In[ ]:


# Plot Sex values
plt.figure(figsize=(14,4))
plt.title('Number of survivals by Sex')
sns.countplot(x='Sex', hue=label_col, data=train_data)


# We can see that most males died, whereas most females survived.

# In[ ]:


# Plot Age values
plt.figure(figsize=(14,4))
plt.title('Number of survivals by Age')
sns.distplot( train_data.loc[(train_data.Survived == 0)]["Age"], color="red", bins=20, label="Died")
sns.distplot( train_data.loc[(train_data.Survived == 1)]["Age"], color="lightgreen", bins=20, label="Survived")
plt.legend()


# We can see that infants and early teens had a better chance of survival, along with passengers in their mid to late 30's. While passengers in other age groups were more likely to die.

# In[ ]:


# Plot SibSp values
plt.figure(figsize=(14,4))
plt.title('Number of survivals by SibSp')
sns.countplot(x='SibSp', hue=label_col, data=train_data)


# This column is tricky because it can either be a count of the number of siblings (if the passenger is a child), or if they had a spouse (if the passenger is an adult). It'll need further analysis by combining it with age and perhaps the title. We can see that a passenger was more likely to die if they were travelling alone, but if a passenger had one sibling or a spouse they had slightly better odds of surviving. Larger family units appear to have a lower chance of survival.

# In[ ]:


# Plot Parch values
plt.figure(figsize=(14,4))
plt.title('Number of survivals by Parch')
sns.countplot(x='Parch', hue=label_col, data=train_data)


# This column is also tricky because it can either be a count of the number of parents (if the passenger is a child), or the number of children (if the passenger is an adult). Again it'll need further analysis by combining it with age and perhaps the title. We can see that a passenger was more likely to die if they were travelling alone, but if a passenger had one child or one parent they had slightly better odds of surviving. Larger family units appear to have a lower chance of survival.

# In[ ]:


#Inspect Ticket values
train_data[['Ticket', 'Name', 'Pclass', 'Fare', 'Survived']].sort_values(by='Ticket', ascending=False).head(20)


# We can see that some passengers share the same ticket number, and others have a consecutive numbers, which could help in identifying family units.

# In[ ]:


# Plot Fare values
plt.figure(figsize=(14,4))
plt.title('Number of survivals by Fare')
sns.distplot( train_data.loc[(train_data.Survived == 0)]["Fare"], color="red", bins=20, label="Died")
sns.distplot( train_data.loc[(train_data.Survived == 1)]["Fare"], color="lightgreen", bins=20, label="Survived")
plt.legend()


# We can see that passengers who bought the cheapest tickets were most likely to die, while the majority of people with more expensive tickets survived.

# In[ ]:


# Inspect Cabin values
train_data[['Cabin', 'Name', 'Pclass', 'Fare', 'Survived']].sort_values(by='Cabin', ascending=False).head(20)


# With nearly 80% of the Cabin data missing, it is very unlikely that the missing values can be imputed, therefore this column will probably need to be excluded as a feature in the model. It could however assist with identifying family units.

# In[ ]:


# Plot Embarked values
plt.figure(figsize=(14,4))
plt.title('Number of survivals by Embarked')
sns.countplot(x='Embarked', hue=label_col, data=train_data)


# We can see that the majority of passengers embarked from "S", and a large majority of those died. The survival rate of passengers that embarked from "C" and "Q" appear to be more evenly split.

# ### **Summary**
# There is a lot of data missing in one of the columns but the rest of the missing data can be imputed.
# The data seems to support the harsh reality that wealth and privilage gives people a head start in all aspects of life. It also suggests that women and children were given priority access to the life boats. Another observation is that larger family units were less likely to survive.
# Analysing the data gives you valuable insight into the dataset. This will help guide decisions in the next step which is called Feature Engineering.
