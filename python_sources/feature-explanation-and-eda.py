#!/usr/bin/env python
# coding: utf-8

# In[ ]:


# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load in 

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import seaborn as sns
sns.set()
from matplotlib import pyplot as plt
import warnings
from sklearn.preprocessing import StandardScaler
#Ignore filter warnings
warnings.filterwarnings("ignore")

#By default, Pandas displays 20 columns and 60 rows, I will increase it to 150 and 100
pd.set_option('display.max_columns', 150)
pd.set_option('display.max_rows', 100)


# # <center>
# <img align="center" src="http://www.jcytol.org/articles/2016/33/4/images/JCytol_2016_33_4_182_190449_f1.jpg">
# <br>
#     
# Hello Kagglers! This work is part of my Capstone project in Data Analytics, Predictive Analytics and Big Data course at Ryerson University, Toronto, so I would really appreciate your upvote or suggestions for improvement.
# 
# The "Diagnostic Wisconsin Breast Cancer Database" is a publicly available data set from the UCI machine learning repository. The dataset gives information about tumor features, that are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. For each observation there are 10 features, which describe tumor size, density, texture, symmetry, and other characteristics of the cell nuclei present in the image. The mean, standard error and "worst" mean (mean of the three largest values) of these features were computed for each image, resulting in 30 features. The categorical target feature indicates the type of the tumor.
# 
# The area on the aspirate slides to be analyzed was visually selected for minimal nuclear overlap. The image for digital analysis was generated by a JVC TK-1070U color video camera mounted above an Olympus microscope and the image was projected into the camera with a 63 x objective and a 2.5 x ocular. The image was captured as a 512 x 480 resolution, 8 bit/pixel (Black and White) file. The aspirated material was expressed onto a silane-coated glass slide, which was placed under a similar slide. A typical image contains approximately from 10 to 40 nuclei. After computing 10 features for each nucleus, the mean, standart error and extreme value was computed, as it mentioned above. These features are modeled such that higher values are typically associated with malignancy. 
# 
# Let's load our dataset as a dataframe and explore what kind of features are given along with their datatypes.

# In[ ]:


df = pd.read_csv("../input/data.csv", index_col = 'id')


# In[ ]:


df.head()


# From the database description, features like radius, perimeter, area are perfect comprehensible to me. But what do texture, smoothness, compactness, concavity, symmetry and fractal dimensions mean exactly?
# 
# Texture is a standard deviation of gray-scale values. Each pixel of an image is represented by the 8-bit integer, or *a byte*, from 0 to 255 providing the *amount* of light, where 0 is clear black and 255 is clear white. The darker the image is the lower is the mean of intensity level of a pixel, i.e. byte. 
# So, the SD of gray-scale values means how intense levels are spread for particular individual cells. The higher SD the more contrasting the image is.
# 
# Next, smoothness is quantified by measuring the difference between length of radial line and the mean length of two radial lines surrounding it
#     
# # <center>
# <img align="center" src="https://www.researchgate.net/profile/Nick_Street/publication/268356328/figure/fig3/AS:648234070442001@1531562454255/Line-segments-used-to-compute-smoothness-The-diierence-in-length-of-the-radial.png">
# <br> 
# If the number is small, then the contour is smooth in that region:
# 
# $$ smoothness = \frac{\sum\limits_{i}\left|r_i - \frac{r_{i-1}+r_{i+1}}{2}\right|}{perimeter}$$ 
# 
# The concavity is captured by drawing chords between two boundary points, which lie outside the nuclear. For the concavity_mean the mean value of these lengths is calculated.
# 
# # <center>
# <img align="center" src="https://www.researchgate.net/profile/Nick_Street/publication/268356328/figure/fig4/AS:648234070466567@1531562454273/Line-segments-used-to-compute-concavity-and-concave-points-The-bold-line-segment.png">
# <br> 
# In order to measure symmetry, the major axis, or longest chord through the center, is found. We then measure the length difference between lines perpendicular to the major axis and the nuclear boundary in both directions.
#     
#    # <center>
# <img align="center" src="https://www.researchgate.net/profile/Nick_Street/publication/268356328/figure/fig5/AS:648234070458368@1531562454289/Line-segments-used-to-compute-symmetry-The-lengths-of-perpendicular-segments-on-the.png">
# <br> 
#     
# Fractal dimensions is approximated using the coastline approximation: the perimeter of the nucleaus is measured by a using increasingly larger rulers, and as the ruler size increases, the perimeter decreases. Plotting log transformation of the perimeter against log of the ruler size and measuring the downward slope gives us the fractal dimension. As with all the shape features, a higher value corresponds to a less regular contour and thus to a higher probability of malignancy.
# 
# Let's look at the general statistics. including mean, std, median, percentiles, and range.

# In[ ]:


df.describe().T


# ![](http://)Let's have a look how the target class is distributed:

# In[ ]:


df['diagnosis'].value_counts(normalize=True)


# In[ ]:


#And convert it to categorical feature:
df['diagnosis'] = df['diagnosis'].astype('category')
df.info()


# ![](http://)As it can be seen, there is no missing values, except for the last column. All independent features are numerical and the target feature is converted to categorical.

# In[ ]:


#Remove the last empty column
df.drop('Unnamed: 32',axis = 1 ,inplace = True)


# It might be usiful to convert the target class denoting malignant as 0 and benign as 1, and examine correlation among variables:

# In[ ]:


df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B':0})
corr = df.corr()
cmap = sns.diverging_palette(220, 10, as_cmap=True)

# Set up the matplotlib figure
f, ax = plt.subplots(figsize=(21, 19))
# Draw the heatmap with the mask and correct aspect ratio
sns.heatmap(corr, cmap=cmap, center=0,annot = True,
            square=True, linewidths=.5, cbar_kws={"shrink": .5});


# There are strong positive linear relationships between malignancy and radius of nuclear, number of concave points, perimeter and area. That is not surprising, as these features were modeled in such way that higher values are typically associated with malignancy. To examine *multicollinearity* I will look at pairwise scatter plots of pairs of first 10 and last 10 variables (in the sake of simplicity and visualization), looking for near perfect relationships. 

# In[ ]:


means = [col for col in df.columns if col.endswith('_mean')]
se = [col for col in df.columns if col.endswith('_se')]
worst = [col for col in df.columns if col.endswith('_worst')]


# In[ ]:


get_ipython().run_line_magic('config', "InlineBackend.figure_format = 'png'")
means_and_worst = pd.merge(df[means],df[worst],left_index= True,right_index= True, how = "left")
sns.pairplot(means_and_worst);


# Next, let's see how means are distributed among target class:

# In[ ]:


means = [col for col in df.columns if col.endswith('_mean')]
se = [col for col in df.columns if col.endswith('_se')]
worst = [col for col in df.columns if col.endswith('_worst')]


# I standartized variables, as their ranges are quite different and not representable on a small graph. Every `violinplot` includes markers indicating the median and the interquartile (middle 50%) range. In first nine features the median of malignant tumor is easily contrasted with the benign. Generally speaking, for the benign mass the median is lower for all features, which makes sense, because features were modeled such that higher values are typically associated with malignancy. 
# 
# For example,`area_mean` is higher for cancerous mass on average.
# 
# Let's look at the standart deviation of features:

# In[ ]:


df.groupby(['diagnosis'])['area_mean'].mean()


# In[ ]:


def plot_violinplot(feat_list):
    scaler = StandardScaler()
    feat_scaled = pd.DataFrame(scaler.fit_transform(df[feat_list]),columns=feat_list, index = df.index)
    data = pd.concat([df['diagnosis'],feat_scaled],axis=1)
    df_melt = pd.melt(frame=data, value_vars=feat_list, id_vars=['diagnosis'])
    fig, ax = plt.subplots(1, 1, figsize = (15, 15), dpi=300)
    sns.violinplot(x="variable",y="value",hue = "diagnosis",data=df_melt,split = True, inner="quart",palette='Set2').set_title('Distribution of features among malignant and benign tumours'.format(feat_list))
    plt.xticks(rotation=45)
    L=plt.legend()
    L.get_texts()[0].set_text('Benign')
    L.get_texts()[1].set_text('Malignant')


# In[ ]:


plot_violinplot(means)


# In[ ]:


plot_violinplot(se)


# To interpret these results, the area, radius, perimeter of cancerous cells are widely distributed and dramatically vary from cell to cell in the cytology slide, as well as the number of concave points vary broadly for malignant nuclei.
# 
# And, finally, the worst, i.e. mean of the three largest values:

# In[ ]:


plot_violinplot(worst)


# In[ ]:


#Cross table break down by diagnosis
numerical = df.drop('diagnosis',axis=1).columns
df.groupby(['diagnosis'])[numerical].agg([np.mean, np.std, np.min, np.max])


# The next step will be [Principal Component Analysis](https://www.kaggle.com/sulianova/kernelc4a2512f08) 
