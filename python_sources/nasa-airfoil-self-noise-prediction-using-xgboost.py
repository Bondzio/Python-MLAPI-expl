#!/usr/bin/env python
# coding: utf-8

# In this notebook, we will be exploring and using different machine learning models to analyze and predict self-noise generated by the NACA 0012 Airfoil due to flow of air around it. A further explanation of the mechanism is detailed in the paper by Brooks et. al. and subsequent papers where the authors attemp to predict self-noise using Artificial Neural Networks. Using this method yields a highly accurate model, however, it takes significant computational resources to train. This ANN model also has the potential to overfit the data.
# 
# Hence, I decided to test the effectiveness of using simpler models such as Random Forest Regression and Extreme Gradient Boosting Regression to develop an accurate model. Through an iterative approach by tuning the hyperparameters, I was able to obtain ~94% cross-validated accuracy for the XG Boost model and ~92% cross-validated accuracy for the Random Forest model. This demonstrates the viability of using such models to model complex data.

# In[ ]:


import numpy as np
import pandas as pd 
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn import model_selection
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
from xgboost import XGBRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.model_selection import GridSearchCV

get_ipython().run_line_magic('matplotlib', 'inline')
import os
print(os.listdir("../input"))


# # Importing Data

# Here, the data is imported and plots between different variables are plotted in order to observe correlations between variables.
# 
# The independent variables are as follows:
# * Frequency (Hz)
# * Angle of Attack (deg)
# * Chord Length (m)
# * Free-stream velocity (m/s)
# * Suction side displacement thickness (m)
# 
# The dependent variable is:
# * Scaled sound pressure level (dB)

# In[ ]:


file = '../input/airfoil.csv'
airfoil_data = pd.read_csv(file, header=None)
airfoil_data.columns = ['frequency', 'angle_of_attack', 'chord', 'velocity', 'suc_displacement', 'sound_pressure']
sns.pairplot(data=airfoil_data)


# # Splitting and Scaling Data

# Since the features vary in terms of orders of magnitude, feature scaling is applied to yield a better fit to the model and increase efficiency of gradient descent. Since the data is not normally distributed (or close to it), a simple min max scaling is applied. The data is also split in terms of input and output variables.

# In[ ]:


y = airfoil_data.sound_pressure
features = ['frequency', 'angle_of_attack', 'chord', 'velocity', 'suc_displacement']
X = airfoil_data[features]
y = y.to_frame()


# In[ ]:


from sklearn import preprocessing
scaler_x = preprocessing.MinMaxScaler()
X_scaled = scaler_x.fit_transform(X)
scaler_y = preprocessing.MinMaxScaler()
y_scaled = scaler_y.fit_transform(np.array(y).reshape(-1,1))
y_scaled = y_scaled.reshape(-1)
train_X, val_X, train_y, val_y = train_test_split(X_scaled, y_scaled, random_state=1)
val_y = scaler_y.inverse_transform(np.array(val_y).reshape(-1,1))


# # Comparing Different Models

# Here, different regression models are compared in terms of their accuracy. The predicted results are 10 fold cross validated to demonstrate their robustness.

# In[ ]:


def compare_models(a,b,c,d):
    print('\nCompare Multiple Classifiers:')
    print('\nK-Fold Cross-Validation Accuracy:\n')
    models = []
    models.append(('LR', LinearRegression()))
    models.append(('RF', RandomForestRegressor(n_estimators=10)))
    models.append(('DT', DecisionTreeRegressor()))
    models.append(('XGB', XGBRegressor()))
    models.append(('SVR RBF', SVR(gamma='auto')))
    models.append(('SVR Lin', SVR(kernel='linear', gamma='auto')))
    resultsAccuracy = []
    names = []
    for name, model in models:
        model.fit(a,b)
        kfold = model_selection.KFold(n_splits=10, random_state=7)
        accuracy_results = model_selection.cross_val_score(model, a,b, cv=kfold)
        resultsAccuracy.append(accuracy_results)
        names.append(name)
        accuracyMessage = "%s: %f (%f)" % (name, accuracy_results.mean(), accuracy_results.std())
        print(accuracyMessage)
        
    # boxplot algorithm comparison
    fig = plt.figure()
    fig.suptitle('Algorithm Comparison: Accuracy')
    ax = fig.add_subplot(111)
    plt.boxplot(resultsAccuracy)
    ax.set_xticklabels(names)
    ax.set_ylabel('Cross-Validation: Accuracy Score')
    plt.show()
    return

compare_models(train_X, train_y, val_X, val_y)


# # Random Forest Regressor

# Since it can be observed that the Random Forest Regressor performed the best, I decided to further explore the algorithm's capabilities by tuning the hyperparameters. By increasing the number of estimators, the maximum absolute error decreased considerably.

# In[ ]:


rf_model = RandomForestRegressor(n_estimators=100, random_state=1)
rf_model.fit(train_X, train_y)
rf_val_predictions = rf_model.predict(val_X)
rf_val_predictions = scaler_y.inverse_transform(np.array(rf_val_predictions).reshape(-1,1))

rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)
print("Validation MAE when using Random Forest {}".format(rf_val_mae))
val_r2 = r2_score(val_y, rf_val_predictions)
print("Validation R^2: {}".format(val_r2))
kfold = model_selection.KFold(n_splits=10, random_state=7)
accuracy_results = model_selection.cross_val_score(rf_model, train_X,train_y, cv=kfold)
accuracyMessage = "%s: %f (%f)" % ('RF Cross Validation', accuracy_results.mean(), accuracy_results.std())
print(accuracyMessage)


# In[ ]:


fig, ax = plt.subplots()
ax.scatter(val_y, rf_val_predictions)
ax.plot([val_y.min(), val_y.max()], [rf_val_predictions.min(), rf_val_predictions.max()], 'k--', lw=4)
ax.set_xlabel('Measured')
ax.set_ylabel('Predicted')
plt.show()


# # XGBoost

# The second algorithm I decided to evaluate is the Extreme Gradient Boosting Regressor algorithm. Here, tuning the hyperparameters resulted in a much higher cross validated accuracy by more than 10%, exceeding the Random Forest Regressor accuracy. Increasing the learning rate and the number of estimators yielded this result.

# In[ ]:


xg_model = xgb.XGBRegressor(learning_rate=0.2, max_depth=6, n_estimators=200, random_state=1)
xg_model.fit(train_X, train_y)
xg_preds = xg_model.predict(val_X)
xg_preds = scaler_y.inverse_transform(np.array(xg_preds).reshape(-1,1))
xg_mae = mean_squared_error(xg_preds, val_y)
print("Validation MSE when using Gradient Boost {}".format(xg_mae))
val_r2 = r2_score(val_y, xg_preds)
print("Validation R^2: {}".format(val_r2))

kfold = model_selection.KFold(n_splits=10, random_state=7)
accuracy_results = model_selection.cross_val_score(xg_model, train_X,train_y, cv=kfold)
accuracyMessage = "%s: %f (%f)" % ('XGB Cross Validation', accuracy_results.mean(), accuracy_results.std())
print(accuracyMessage)


# In[ ]:


fig, ax = plt.subplots()
ax.scatter(val_y, xg_preds)
ax.plot([val_y.min(), val_y.max()], [xg_preds.min(), xg_preds.max()], 'k--', lw=4)
ax.set_xlabel('Measured')
ax.set_ylabel('Predicted')
plt.show()


# # Conclusion

# This exploration demonstrated that hyperparameter tuning of certain models can increase the accuracy of simple models significantly. Finally, we are now able to predict Airfoil Self-Noise to a reasonable degree of accuracy without overfitting/underfitting or using a complex Neural Network. These models have scope for improvement, and more precise hyperparameter tuning can lead to a more accurate model.
