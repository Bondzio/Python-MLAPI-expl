#!/usr/bin/env python
# coding: utf-8

# ## A starter code
# To begin exploratory analysis, first import libraries and define functions for plotting the data

# In[ ]:


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os


# In[ ]:


# Distribution graphs (histogram/bar graph) of column data
def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):
    nunique = df.nunique()
    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values
    nRow, nCol = df.shape
    columnNames = list(df)
    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow
    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')
    for i in range(min(nCol, nGraphShown)):
        plt.subplot(nGraphRow, nGraphPerRow, i + 1)
        columnDf = df.iloc[:, i]
        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):
            valueCounts = columnDf.value_counts()
            valueCounts.plot.bar()
        else:
            columnDf.hist()
        plt.ylabel('counts')
        plt.xticks(rotation = 90)
        plt.title(f'{columnNames[i]} (column {i})')
    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)
    plt.show()


# ### Load ssd_reviews.csv file

# In[ ]:


df1 = pd.read_csv('../input/ssd-reviews/ssd_reviews.csv')
nRow, nCol = df1.shape
print(f'There are {nRow} rows and {nCol} columns')
# df1.drop(columns='Unnamed: 0', axis=1, inplace=True)


# Let's take a quick look at what the data looks like:

# In[ ]:


df1.head()


# In[ ]:


df1.info()


# In[ ]:


df1['date'] = pd.to_datetime(df1['date']) # we can change date column from object to datetime
df1.drop(columns='Unnamed: 0', axis=1, inplace=True) # And we can drop this column generated by kaggle


# ## Exploratory analysis

# Distribution graphs (histogram/bar graph) of sampled columns:

# In[ ]:


plotPerColumnDistribution(df1, 10, 5)


# In[ ]:


df1['ownership_pariod'].value_counts()   #Look at data_description.txt file for more information


# In[ ]:


df1['rating_stars'].value_counts()   #Look at data_description.txt file for more information


# In[ ]:


df1['year'].value_counts()   #Look at data_description.txt file for more information


# In[ ]:


df1['month'].value_counts()   #Look at data_description.txt file for more information


# In[ ]:


df1['day'].value_counts()   #Look at data_description.txt file for more information


# # Suggestions :

# <b> Suggestions for modeling: <br>
# create two additional columns, the first one contains both (pros and cons) in the same column, and the second column contains (0 and 1), So if the value in the new column (pros and cons) is pros then put 1, And if the value is cons then put 0 </b>

# <b> Since we have pros and cons data, we don't need to add more products to the dataset, Because when we want to do a Sentiment analysis, the pros and cons will be in the same column, So the Sentiment analysis training will consider cons as negative and pros as positive, And from that our model will be balanced.</b>

# #### Enjoy modeling ..
