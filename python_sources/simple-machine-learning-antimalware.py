#!/usr/bin/env python
# coding: utf-8

# ## Simple Machine Learning Antimalware in Python
# I'll try to explain how can you use the **Benign & Malicious PE Files** dataset.
# 
# I built the dataset with Python pefile library. The malwares are from [VirusShare](https://virusshare.com/) and the benign software are from a windows server SO.

# In[15]:


#Import the libraries
import numpy as np
import pandas as pd
import seaborn as sns
import pickle as pck
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
get_ipython().run_line_magic('matplotlib', 'inline')


# > You can check my [github](https://github.com/amauricio/sklearn-antimalware) to learn how to capture new data from Malwares.

# In[16]:


#Loading dataset from training
data = pd.read_csv('../input/dataset_malwares.csv', sep=',')

#The target is Malware Column {0=Benign, 1=Malware}
X = data.drop(['Name','Malware'], axis=1)
y = data['Malware']

X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.2, random_state=101)
X_train.head()


# In[5]:


scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_train)


# In[17]:


X_new = pd.DataFrame(X_scaled, columns=X.columns)
X_new.head()


# In[20]:


skpca = PCA(n_components=55)
X_pca = skpca.fit_transform(X_new)
print('Variance sum : ', skpca.explained_variance_ratio_.cumsum()[-1])


# In[21]:


from sklearn.ensemble import RandomForestClassifier as RFC
from sklearn.metrics import classification_report, confusion_matrix


# In[22]:


model = RFC(n_estimators=100, random_state=0, 
                         oob_score = True,
                         max_depth = 16, 
                         max_features = 'sqrt')
model.fit(X_pca, y_train)

X_test_scaled = scaler.transform(X_test)
X_test_new = pd.DataFrame(X_test_scaled, columns=X.columns)
X_test_pca = skpca.transform(X_test_new)

y_pred = model.predict(X_test_pca)
print(classification_report(y_pred, y_test))


# In[23]:


sns.heatmap(confusion_matrix(y_pred, y_test), annot=True, fmt="d", cmap=plt.cm.Blues, cbar=False)


# In[24]:


from sklearn.externals import joblib
from sklearn.pipeline import Pipeline
pipe = Pipeline([('scale', scaler),('pca', skpca), ('clf', model)])
# jbolib.dumps(pipe, 'my_model')


# > Maybe you want save the model to use it later without need to do the training again.

# In[27]:


test = pd.read_csv('../input/dataset_test.csv', sep=',')

X_to_push = test
X_testing = test.drop(['Name'], axis=1)


clf = pipe
X_testing_scaled = clf.named_steps['scale'].transform(X_testing)
X_testing_pca = clf.named_steps['pca'].transform(X_testing_scaled)
y_testing_pred = clf.named_steps['clf'].predict_proba(X_testing_pca)
pd.concat([X_to_push['Name'], pd.DataFrame(y_testing_pred) ], axis=1)


# In[ ]:




