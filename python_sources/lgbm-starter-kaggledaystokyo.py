#!/usr/bin/env python
# coding: utf-8

# In[ ]:


# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load in 

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# Any results you write to the current directory are saved as output.


# In[ ]:


get_ipython().run_cell_magic('time', '', "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import OneHotEncoder,LabelEncoder\npd.set_option('display.max_rows', 1000)\npd.set_option('display.max_columns', 1000)\npd.set_option('display.width', 1000)\npd.set_option('display.max_colwidth', 1000)\n\ntrain = pd.read_csv('/kaggle/input/kaggle-days-tokyo/train.csv')\ntrain['flag'] = 1\ntest = pd.read_csv('/kaggle/input/kaggle-days-tokyo/test.csv')\ntest['flag'] = 0\ndf = pd.concat([train,test],axis=0)\ndf = df.sort_values(by=['ts']).reset_index()\n\n\nkiji = pd.read_csv('/kaggle/input/kaggle-days-tokyo/kiji_metadata.csv').rename(columns={'kiji_id_raw': 'kiji_id'})\ndf = pd.merge(df, kiji, on='kiji_id', how='left')\n\ndef date_time(df):\n    df['ts'] = pd.to_datetime(df['ts'],utc=True)\n    df['display_time'] = pd.to_datetime(df['display_time'],utc=True)\n    \n    df['dayofweek'] = df['ts'].dt.dayofweek\n    df['is_weekend'] = (df['ts'].dt.weekday >=5).astype(int)\n    df['hour'] = df['ts'].dt.hour\n    df['minute'] = df['ts'].dt.minute\n    df['second'] = df['ts'].dt.second\n    \n    df['display_dayofweek'] = df['display_time'].dt.dayofweek\n    df['display_hour'] = df['display_time'].dt.hour\n    df['display_minute'] = df['display_time'].dt.minute\n    df['display_second'] = df['display_time'].dt.second\n    \n    df['days_from_display'] = (df['ts'] - df['display_time']).dt.days\n    df['seconds_from_display'] = (df['ts'] - df['display_time']).dt.seconds\n    df['hours_from_display'] = df['seconds_from_display'] // 3600\n    df['minutes_from_display'] = df['seconds_from_display'] //60\n    \n    return df\n\ndef lbl_enc(df):\n    for c in ['kiji_id','er_dev_browser_family', 'er_dev_browser_version', 'er_dev_device_name', \n            'er_dev_device_type', 'er_dev_manufacture', 'er_dev_os_family', 'er_dev_os_version',\n            'er_geo_bc_flag', 'er_geo_city_j_name', 'er_geo_country_code', 'er_geo_pref_j_name', \n            'er_rfc_kiji_id_raw', 'er_rfs_reffered_visit', 'er_rfs_service_name', 'er_rfs_service_type',\n             'ig_ctx_product','ig_usr_connection',\n             'service_category', 'title', 'title2', 'title3', 'genres', 'belong_topic_info', 'keywords', 'body',]:\n        if df[c].dtype == 'object':\n            lbl = LabelEncoder()\n            df[c] = lbl.fit_transform(df[c].fillna('NA').astype(str))\n    return df\n\ndf = date_time(df)\ndf = lbl_enc(df)")


# In[ ]:


get_ipython().run_cell_magic('time', '', "for cat_col in ['er_dev_browser_version','hour','ig_ctx_product','er_rfc_kiji_id_raw','er_dev_os_version','genres']:\n    print (cat_col)\n    for num_col in ['ig_ctx_red_elapsed_since_page_load','ig_ctx_red_viewed_percent', 'seconds_from_display']:\n        print (num_col)\n        df['sum_' + str(cat_col) + '_' + str(num_col)] = df.groupby([cat_col])[num_col].transform(sum)\n        df['mean_' + str(cat_col) + '_' + str(num_col)] = df.groupby([cat_col])[num_col].transform(np.mean)\n        df['min_' + str(cat_col) + '_' + str(num_col)] = df.groupby([cat_col])[num_col].transform(min)\n        df['max_' + str(cat_col) + '_' + str(num_col)] = df.groupby([cat_col])[num_col].transform(max)\n        df['median_' + str(cat_col) + '_' + str(num_col)] = df.groupby([cat_col])[num_col].transform(np.median)\n        df['std_' + str(cat_col) + '_' + str(num_col)] = df.groupby([cat_col])[num_col].transform(np.std)\n        ")


# In[ ]:


get_ipython().run_cell_magic('time', '', "from scipy.stats import mode\ndef mod(arr):\n    return mode(arr)[0][0]   \n\ndf_uid = pd.DataFrame(df.user_id.unique(),columns=['user_id'])\n\ndf_uid['age'] = df_uid['user_id'].map(df.groupby(['user_id'])['age'].mean())\ndf_uid['flag'] = df_uid['user_id'].map(df.groupby(['user_id'])['flag'].mean())\ndf_uid['kiji_count'] = df_uid['user_id'].map(df.groupby(['user_id'])['kiji_id'].count())\n\nfor col in ['ig_ctx_red_elapsed_since_page_load','ig_ctx_red_viewed_percent',\n            'days_from_display', 'seconds_from_display', 'hours_from_display',\n            'minutes_from_display','moji_count']:\n    print (col)\n    df_uid[col + '_mean'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].mean()) \n    df_uid[col + '_max'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].max()) \n    df_uid[col + '_min'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].min()) \n    df_uid[col + '_median'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].median()) \n    df_uid[col + '_std'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].std()) \n    df_uid[col + '_ptp'] = df_uid[col + '_max'] - df_uid[col + '_min']\n    df_uid[col + '_diff_max_mean'] = df_uid[col + '_max'] - df_uid[col + '_mean']\n    df_uid[col + '_diff_min_mean'] = df_uid[col + '_min'] - df_uid[col + '_mean']\n        \nfor col in ['kiji_id','is_weekend','dayofweek','hour','minute','second','er_dev_browser_family', \n            'er_dev_browser_version', 'er_dev_device_name', \n            'er_dev_device_type', 'er_dev_manufacture', 'er_dev_os_family', 'er_dev_os_version',\n            'er_geo_bc_flag', 'er_geo_city_j_name', 'er_geo_country_code', 'er_geo_pref_j_name', \n            'er_rfc_kiji_id_raw', 'er_rfs_reffered_visit', 'ig_ctx_product', 'ig_usr_connection',\n            'service_category', 'title', 'title2', 'title3', 'genres', 'belong_topic_info', 'keywords', 'body',]:\n    print (col)\n    df_uid[col + '_nunique'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].nunique())\n    df_uid[col + '_mode'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].agg(mod))")


# In[ ]:


get_ipython().run_cell_magic('time', '', "\nsum_cols = [col for col in df if col.startswith('sum_')]\nfor col in sum_cols:\n    print (col)\n    df_uid['sum_' + col + '_mean'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].mean()) \n    df_uid['sum_' + col + '_max'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].max()) \n    df_uid['sum_' + col + '_min'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].min()) \n    df_uid['sum_' + col + '_median'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].median()) \n    df_uid['sum_' + col + '_std'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].std()) \n    df_uid['sum_' + col + '_diff_max_mean'] = df_uid['sum_' + col + '_max'] - df_uid['sum_' + col + '_mean']\n    df_uid['sum_' + col + '_diff_min_mean'] = df_uid['sum_' + col + '_min'] - df_uid['sum_' + col + '_mean']\n    \nmean_cols = [col for col in df if col.startswith('mean_')]\nfor col in mean_cols:\n    print (col)\n    df_uid['mean_' + col + '_mean'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].mean()) \n    df_uid['mean_' + col + '_max'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].max()) \n    df_uid['mean_' + col + '_min'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].min()) \n    df_uid['mean_' + col + '_median'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].median()) \n    df_uid['mean_' + col + '_std'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].std()) \n    df_uid['mean_' + col + '_diff_max_mean'] = df_uid['mean_' + col + '_max'] - df_uid['mean_' + col + '_mean']\n    df_uid['mean_' + col + '_diff_min_mean'] = df_uid['mean_' + col + '_min'] - df_uid['mean_' + col + '_mean']  \n    \nmax_cols = [col for col in df if col.startswith('max_')]\nfor col in max_cols:\n    print (col)\n    df_uid['max_' + col + '_mean'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].mean()) \n    df_uid['max_' + col + '_max'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].max()) \n    df_uid['max_' + col + '_min'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].min()) \n    df_uid['max_' + col + '_median'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].median()) \n    df_uid['max_' + col + '_std'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].std()) \n    df_uid['max_' + col + '_diff_max_mean'] = df_uid['max_' + col + '_max'] - df_uid['max_' + col + '_mean']\n    df_uid['max_' + col + '_diff_min_mean'] = df_uid['max_' + col + '_min'] - df_uid['max_' + col + '_mean']    \n    \nmin_cols = [col for col in df if col.startswith('min_')]\nfor col in min_cols:\n    print (col)\n    df_uid['min_' + col + '_mean'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].mean()) \n    df_uid['min_' + col + '_max'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].max()) \n    df_uid['min_' + col + '_min'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].min()) \n    df_uid['min_' + col + '_median'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].median()) \n    df_uid['min_' + col + '_std'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].std()) \n    df_uid['min_' + col + '_diff_min_mean'] = df_uid['min_' + col + '_max'] - df_uid['min_' + col + '_mean']\n    df_uid['min_' + col + '_diff_min_mean'] = df_uid['min_' + col + '_min'] - df_uid['min_' + col + '_mean']        \n    \nmedian_cols = [col for col in df if col.startswith('median_')]\nfor col in median_cols:\n    print (col)\n    df_uid['median_' + col + '_mean'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].mean()) \n    df_uid['median_' + col + '_max'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].max()) \n    df_uid['median_' + col + '_min'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].min()) \n    df_uid['median_' + col + '_median'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].median()) \n    df_uid['median_' + col + '_std'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].std()) \n    df_uid['median_' + col + '_diff_median_mean'] = df_uid['median_' + col + '_max'] - df_uid['median_' + col + '_mean']\n    df_uid['median_' + col + '_diff_median_mean'] = df_uid['median_' + col + '_min'] - df_uid['median_' + col + '_mean']    \n    \nstd_cols = [col for col in df if col.startswith('std_')]\nfor col in std_cols:\n    print (col)\n    df_uid['std_' + col + '_mean'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].mean()) \n    df_uid['std_' + col + '_max'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].max()) \n    df_uid['std_' + col + '_min'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].min()) \n    df_uid['std_' + col + '_median'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].median()) \n    df_uid['std_' + col + '_std'] = df_uid['user_id'].map(df.groupby(['user_id'])[col].std()) \n    df_uid['std_' + col + '_diff_std_mean'] = df_uid['std_' + col + '_max'] - df_uid['std_' + col + '_mean']\n    df_uid['std_' + col + '_diff_std_mean'] = df_uid['std_' + col + '_min'] - df_uid['std_' + col + '_mean']        ")


# In[ ]:


get_ipython().run_cell_magic('time', '', "mode_cols = ['er_dev_browser_version_mode','ig_ctx_product_mode','er_dev_os_version_mode',\n            'genres_mode','keywords_mode','hour_mode']\nfor m_col in mode_cols:\n    print (m_col)\n    for num_col in ['kiji_count',\n\n                   ]:\n        df_uid['mean_' + m_col + '_' + num_col] = df_uid.groupby([m_col])[num_col].transform(np.mean)\n        df_uid['diff_mean_' + m_col + '_' + num_col] = df_uid['mean_' + m_col + '_' + num_col]  - df_uid[num_col]\n        df_uid['ratio_mean_' + m_col + '_' + num_col] = df_uid['mean_' + m_col + '_' + num_col]  / df_uid[num_col]\n        ")


# In[ ]:


get_ipython().run_cell_magic('time', '', 'import lightgbm as lgb\nfrom sklearn.model_selection import KFold,StratifiedKFold,GroupKFold,RepeatedKFold\nfrom sklearn.metrics import mean_squared_error\n\ndef rmse(y_true, y_pred):\n    return (mean_squared_error(y_true, y_pred))** .5\n\ntrain_df = df_uid[df_uid[\'flag\']==1]\ntest_df = df_uid[df_uid[\'flag\']==0]\n\ndrop_features=[\'user_id\',\'age\',\'flag\']\nfeats = [f for f in train_df.columns if f not in drop_features]\nfeats = [\n"max_max_er_dev_browser_version_ig_ctx_red_viewed_percent_mean",\n"mean_mean_ig_ctx_product_ig_ctx_red_viewed_percent_max",\n"er_geo_bc_flag_mode",\n"sum_sum_er_rfc_kiji_id_raw_seconds_from_display_mean",\n"er_dev_device_type_mode",\n"er_dev_device_name_nunique",\n"median_median_er_dev_browser_version_ig_ctx_red_elapsed_since_page_load_max",\n"sum_sum_er_rfc_kiji_id_raw_ig_ctx_red_viewed_percent_mean",\n"min_min_er_dev_os_version_ig_ctx_red_elapsed_since_page_load_min",\n"std_std_er_dev_browser_version_ig_ctx_red_viewed_percent_max",\n"is_weekend_mode",\n"er_dev_device_type_nunique",\n"er_dev_browser_family_mode",\n"std_std_er_dev_browser_version_seconds_from_display_median",\n"title2_mode",\n"median_median_er_dev_browser_version_ig_ctx_red_elapsed_since_page_load_median",\n"er_dev_browser_family_nunique",\n"mean_mean_er_dev_browser_version_ig_ctx_red_viewed_percent_mean",\n"sum_sum_er_dev_browser_version_ig_ctx_red_elapsed_since_page_load_max",\n"mean_mean_er_dev_browser_version_ig_ctx_red_elapsed_since_page_load_min",\n"sum_sum_ig_ctx_product_ig_ctx_red_elapsed_since_page_load_min",\n"max_max_hour_ig_ctx_red_viewed_percent_max",\n"er_dev_os_family_nunique",\n"sum_sum_er_rfc_kiji_id_raw_seconds_from_display_median",\n"std_std_ig_ctx_product_ig_ctx_red_viewed_percent_mean",\n"max_max_genres_ig_ctx_red_viewed_percent_max",\n"sum_sum_er_dev_browser_version_ig_ctx_red_elapsed_since_page_load_mean",\n"er_geo_bc_flag_nunique",\n"is_weekend_nunique",\n"sum_sum_er_dev_browser_version_seconds_from_display_mean",\n"median_median_er_dev_browser_version_ig_ctx_red_elapsed_since_page_load_min",\n"median_median_er_dev_browser_version_seconds_from_display_min",\n"median_median_er_rfc_kiji_id_raw_ig_ctx_red_elapsed_since_page_load_median",\n"er_dev_browser_version_mode",\n"std_std_genres_ig_ctx_red_elapsed_since_page_load_median",\n"mean_mean_genres_seconds_from_display_median",\n"std_std_ig_ctx_product_ig_ctx_red_elapsed_since_page_load_mean",\n"mean_mean_genres_seconds_from_display_max",\n"median_median_er_dev_os_version_ig_ctx_red_elapsed_since_page_load_max",\n"days_from_display_min",\n"mean_mean_ig_ctx_product_ig_ctx_red_viewed_percent_mean",\n"er_dev_device_name_mode",\n"std_std_er_rfc_kiji_id_raw_ig_ctx_red_elapsed_since_page_load_max",\n"median_median_genres_seconds_from_display_median",\n"min_min_er_dev_os_version_ig_ctx_red_elapsed_since_page_load_median",\n"sum_sum_hour_ig_ctx_red_elapsed_since_page_load_mean",\n"ig_ctx_red_elapsed_since_page_load_mean",\n"mean_genres_mode_kiji_count",\n"max_max_er_dev_browser_version_seconds_from_display_max",\n"ig_usr_connection_mode",\n"median_median_hour_ig_ctx_red_elapsed_since_page_load_std",\n"er_dev_os_family_mode",\n"std_std_hour_ig_ctx_red_viewed_percent_max",\n"mean_mean_er_dev_os_version_seconds_from_display_min",\n"min_min_er_dev_browser_version_ig_ctx_red_elapsed_since_page_load_median",\n"median_median_er_dev_os_version_seconds_from_display_min",\n"service_category_nunique",\n"median_median_ig_ctx_product_ig_ctx_red_elapsed_since_page_load_mean",\n"er_dev_os_version_mode",\n"mean_mean_er_dev_browser_version_ig_ctx_red_viewed_percent_max",\n"hours_from_display_median",\n"min_min_ig_ctx_product_ig_ctx_red_elapsed_since_page_load_mean",\n"min_min_er_dev_os_version_ig_ctx_red_elapsed_since_page_load_mean",\n"median_median_er_rfc_kiji_id_raw_ig_ctx_red_elapsed_since_page_load_max",\n"mean_mean_ig_ctx_product_seconds_from_display_diff_max_mean",\n"std_std_er_rfc_kiji_id_raw_seconds_from_display_max",\n"std_std_er_rfc_kiji_id_raw_ig_ctx_red_elapsed_since_page_load_std",\n"std_std_genres_seconds_from_display_min",\n"mean_mean_hour_ig_ctx_red_viewed_percent_max",\n"er_rfc_kiji_id_raw_nunique",\n"max_max_hour_ig_ctx_red_viewed_percent_median",\n"ig_ctx_red_elapsed_since_page_load_median",\n"mean_mean_genres_ig_ctx_red_viewed_percent_mean",\n"sum_sum_hour_ig_ctx_red_elapsed_since_page_load_median",\n"max_max_ig_ctx_product_ig_ctx_red_viewed_percent_mean",\n"sum_sum_hour_ig_ctx_red_elapsed_since_page_load_max",\n"max_max_er_dev_browser_version_seconds_from_display_min",\n"std_std_er_dev_os_version_ig_ctx_red_viewed_percent_max",\n"median_median_er_rfc_kiji_id_raw_ig_ctx_red_elapsed_since_page_load_mean",\n"sum_sum_er_rfc_kiji_id_raw_ig_ctx_red_elapsed_since_page_load_median",\n"std_std_genres_ig_ctx_red_viewed_percent_min",\n"max_max_er_rfc_kiji_id_raw_ig_ctx_red_viewed_percent_mean",\n"mean_mean_genres_seconds_from_display_min",\n"sum_sum_hour_seconds_from_display_median",\n"er_geo_city_j_name_nunique",\n"mean_mean_er_dev_browser_version_ig_ctx_red_elapsed_since_page_load_max",\n"median_median_hour_ig_ctx_red_elapsed_since_page_load_max",\n"std_std_er_dev_os_version_ig_ctx_red_viewed_percent_median",\n"er_rfs_reffered_visit_nunique",\n"std_std_hour_ig_ctx_red_elapsed_since_page_load_mean",\n"sum_sum_genres_seconds_from_display_std",\n"sum_sum_er_dev_browser_version_ig_ctx_red_elapsed_since_page_load_min",\n"sum_sum_er_dev_browser_version_ig_ctx_red_viewed_percent_std",\n"seconds_from_display_median",\n"std_std_hour_ig_ctx_red_elapsed_since_page_load_median",\n"sum_sum_hour_ig_ctx_red_viewed_percent_median",\n"max_max_genres_ig_ctx_red_elapsed_since_page_load_median",\n"sum_sum_hour_seconds_from_display_mean",\n"ig_ctx_red_elapsed_since_page_load_min",\n"sum_sum_hour_ig_ctx_red_elapsed_since_page_load_min",\n"ig_ctx_red_elapsed_since_page_load_std",\n"ig_ctx_red_viewed_percent_diff_max_mean",\n"er_geo_pref_j_name_nunique",\n"sum_sum_er_dev_browser_version_ig_ctx_red_viewed_percent_mean",\n"mean_mean_er_dev_os_version_seconds_from_display_mean",\n"days_from_display_mean",\n"mean_mean_hour_ig_ctx_red_elapsed_since_page_load_median",\n"median_median_er_dev_os_version_seconds_from_display_std",\n"mean_mean_genres_ig_ctx_red_elapsed_since_page_load_median",\n"max_max_ig_ctx_product_seconds_from_display_diff_min_mean",\n"mean_mean_hour_seconds_from_display_mean",\n"ig_ctx_red_viewed_percent_std",\n"min_min_genres_ig_ctx_red_viewed_percent_diff_min_mean",\n"mean_hour_mode_kiji_count",\n"min_min_hour_seconds_from_display_min",\n"max_max_er_dev_os_version_seconds_from_display_min",\n"max_max_er_rfc_kiji_id_raw_ig_ctx_red_viewed_percent_diff_max_mean",\n"sum_sum_ig_ctx_product_ig_ctx_red_elapsed_since_page_load_mean",\n"median_median_ig_ctx_product_seconds_from_display_mean",\n"moji_count_max",\n"days_from_display_std",\n"sum_sum_hour_ig_ctx_red_viewed_percent_mean",\n"median_median_er_dev_os_version_seconds_from_display_median",\n"sum_sum_er_dev_os_version_ig_ctx_red_elapsed_since_page_load_mean",\n"moji_count_mean",\n#"days_from_display_sum",\n"max_max_ig_ctx_product_ig_ctx_red_elapsed_since_page_load_diff_min_mean",\n"hour_mode",\n"sum_sum_er_dev_browser_version_ig_ctx_red_viewed_percent_min",\n"keywords_nunique",\n"max_max_ig_ctx_product_ig_ctx_red_elapsed_since_page_load_diff_max_mean",\n"max_max_hour_ig_ctx_red_elapsed_since_page_load_min",\n"sum_sum_er_rfc_kiji_id_raw_seconds_from_display_min",\n"max_max_er_dev_os_version_ig_ctx_red_elapsed_since_page_load_min",\n"std_std_genres_ig_ctx_red_elapsed_since_page_load_mean",\n"moji_count_median",\n"std_std_genres_seconds_from_display_max",\n"moji_count_std",\n"std_std_genres_seconds_from_display_median",\n"sum_sum_genres_seconds_from_display_median",\n"max_max_er_rfc_kiji_id_raw_ig_ctx_red_viewed_percent_std",\n"mean_mean_er_dev_os_version_ig_ctx_red_elapsed_since_page_load_mean",\n"sum_sum_genres_ig_ctx_red_viewed_percent_std",\n"max_max_ig_ctx_product_seconds_from_display_mean",\n"mean_mean_er_rfc_kiji_id_raw_ig_ctx_red_elapsed_since_page_load_mean",\n"median_median_hour_seconds_from_display_max",\n"keywords_mode",\n"median_median_er_dev_os_version_seconds_from_display_mean",\n"ig_ctx_red_elapsed_since_page_load_diff_min_mean",\n"mean_mean_genres_ig_ctx_red_viewed_percent_median",\n"dayofweek_nunique",\n"median_median_er_rfc_kiji_id_raw_seconds_from_display_median",\n"std_std_genres_ig_ctx_red_viewed_percent_mean",\n"median_median_genres_ig_ctx_red_elapsed_since_page_load_mean",\n"mean_mean_er_dev_os_version_ig_ctx_red_elapsed_since_page_load_min",\n"mean_mean_hour_ig_ctx_red_elapsed_since_page_load_min",\n"sum_sum_genres_ig_ctx_red_elapsed_since_page_load_median",\n"std_std_er_dev_browser_version_ig_ctx_red_viewed_percent_min",\n"mean_er_dev_os_version_mode_kiji_count",\n"median_median_genres_ig_ctx_red_elapsed_since_page_load_max",\n"ig_ctx_red_viewed_percent_min",\n"ig_ctx_red_viewed_percent_mean",\n"min_min_genres_ig_ctx_red_viewed_percent_max",\n"max_max_er_rfc_kiji_id_raw_ig_ctx_red_elapsed_since_page_load_std",\n"median_median_genres_ig_ctx_red_elapsed_since_page_load_std",\n"mean_mean_er_dev_browser_version_ig_ctx_red_elapsed_since_page_load_mean",\n"ig_ctx_red_viewed_percent_median",\n"ig_ctx_red_viewed_percent_ptp",\n"mean_mean_er_rfc_kiji_id_raw_seconds_from_display_diff_min_mean",\n"min_min_er_dev_browser_version_ig_ctx_red_elapsed_since_page_load_max",\n"std_std_er_rfc_kiji_id_raw_ig_ctx_red_viewed_percent_max",\n"std_std_hour_ig_ctx_red_elapsed_since_page_load_min",\n"max_max_er_dev_browser_version_ig_ctx_red_elapsed_since_page_load_min",\n"sum_sum_er_dev_os_version_ig_ctx_red_elapsed_since_page_load_diff_min_mean",\n"std_std_ig_ctx_product_ig_ctx_red_viewed_percent_std",\n"median_median_er_rfc_kiji_id_raw_seconds_from_display_mean",\n"median_median_er_dev_os_version_seconds_from_display_max",\n"max_max_er_rfc_kiji_id_raw_seconds_from_display_diff_min_mean",\n"hours_from_display_ptp",\n"sum_sum_hour_ig_ctx_red_elapsed_since_page_load_diff_min_mean",\n"sum_sum_genres_ig_ctx_red_elapsed_since_page_load_std",\n"mean_keywords_mode_kiji_count",\n"sum_sum_er_rfc_kiji_id_raw_ig_ctx_red_elapsed_since_page_load_min",\n"sum_sum_er_dev_os_version_ig_ctx_red_viewed_percent_max",\n"mean_mean_er_dev_os_version_ig_ctx_red_elapsed_since_page_load_max",\n"max_max_hour_ig_ctx_red_elapsed_since_page_load_std",\n"median_median_er_dev_os_version_ig_ctx_red_elapsed_since_page_load_mean",\n"mean_mean_genres_seconds_from_display_mean",\n"std_std_er_rfc_kiji_id_raw_seconds_from_display_std",\n"genres_mode",\n"min_min_ig_ctx_product_seconds_from_display_mean",\n"er_geo_pref_j_name_mode",\n"mean_mean_er_rfc_kiji_id_raw_ig_ctx_red_elapsed_since_page_load_std",\n"std_std_genres_seconds_from_display_mean",\n"moji_count_diff_min_mean",\n"mean_mean_hour_ig_ctx_red_elapsed_since_page_load_diff_min_mean",\n#"ig_ctx_red_viewed_percent_sum",\n"sum_sum_er_dev_os_version_ig_ctx_red_viewed_percent_diff_min_mean",\n"max_max_hour_seconds_from_display_std",\n"min_min_hour_seconds_from_display_std",\n#"seconds_from_display_sum",\n"title2_nunique",\n"std_std_er_rfc_kiji_id_raw_ig_ctx_red_viewed_percent_std",\n"minutes_from_display_median",\n"sum_sum_genres_ig_ctx_red_elapsed_since_page_load_max",\n"max_max_er_dev_browser_version_seconds_from_display_std",\n"median_median_hour_seconds_from_display_min",\n"median_median_er_dev_os_version_ig_ctx_red_elapsed_since_page_load_std",\n"median_median_er_dev_browser_version_seconds_from_display_std",     \n]\nn_splits= 5\nfolds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=4590)\noof_preds = np.zeros(train_df.shape[0])\nsub_preds = np.zeros(test_df.shape[0])\ncv_list = []\nprint (\'feats:\' + str(len(feats)))\nprint (train_df[feats].shape)\nfor n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df[\'age\'])):\n  \n    train_x, train_y = train_df[feats].iloc[train_idx], train_df[\'age\'].iloc[train_idx]\n    \n    valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df[\'age\'].iloc[valid_idx] \n    \n    print("Train Index:",train_idx,",Val Index:",valid_idx)\n    \n    params = {\n               "objective" : "regression", \n               "boosting" : "gbdt", \n               "metric" : "rmse",  \n               "max_depth": 9, \n               "min_data_in_leaf": 70, \n               "min_gain_to_split": 0.05,\n               "reg_alpha": 0.1, \n               "num_leaves" : 31,\n               "max_bin" : 255, \n               "learning_rate" : 0.02, \n               "bagging_fraction" : 0.8,\n               "bagging_freq" : 1,\n               "bagging_seed" : 4590,\n               "feature_fraction" : 0.7, \n               "verbosity": -1,\n               "random_state": 4590,\n    }\n\n    print("Fold:" + str(n_fold))\n    dtrain = lgb.Dataset(\n            train_x, label=train_y)\n    dval = lgb.Dataset(\n            valid_x, label=valid_y, reference=dtrain,) \n    bst = lgb.train(\n            params, dtrain, num_boost_round=10000,\n            valid_sets=[dval,dtrain],  early_stopping_rounds=200,verbose_eval=100,)\n        \n    new_list = sorted(zip(feats, bst.feature_importance(\'gain\')),key=lambda x: x[1], reverse=True)[:]\n    for item in new_list:\n        print (item) \n\n    oof_preds[valid_idx] = bst.predict(valid_x, num_iteration=bst.best_iteration)#bst.best_iteration\n    oof_cv = rmse(valid_y,  oof_preds[valid_idx])\n    cv_list.append(oof_cv)\n    print (cv_list)\n    sub_preds += bst.predict(test_df[feats], num_iteration=bst.best_iteration) / folds.n_splits # test_df_new\n\ncv = rmse(train_df[\'age\'],  np.round(oof_preds))\nprint(\'Full OOF RMSE %.6f\' % cv) \n\ntrain_df[\'prediction\'] = np.round(oof_preds)\ntrain_df[[\'user_id\',\'prediction\',\'age\']].to_csv(\'oof.csv\',index=False)\n\ntest_df[\'age\'] = np.round(sub_preds)\ntest_df[[\'user_id\',\'age\']].to_csv(\'submission.csv\',index=False)')


# In[ ]:




