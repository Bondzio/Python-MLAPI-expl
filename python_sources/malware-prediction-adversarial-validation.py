#!/usr/bin/env python
# coding: utf-8

# ### Introduction
# One of the most important problems in the [challange to predict malware](https://www.kaggle.com/c/microsoft-malware-prediction) is to find an validation dataset that represents the test. As many commented in the [discussions](http://https://www.kaggle.com/c/microsoft-malware-prediction/discussion/75087), the data for this competition is quite diferent from the train dataset to the test. This kernel has some feature engenieering and adversarial validation made by me and [DimitreOliveira](https://www.kaggle.com/dimitreoliveira) to deal with that problem.
# 
# #### **Table of contents**
# 1. [Simplification of version related features](#Simplification-of-version-related-features);
# 2. [Encoding](#Encoding);
# 3. [Adversarial Validation](#Adversarial-Validation).

# In[1]:


import dask
import dask.dataframe as dd
import warnings
import datetime
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import category_encoders as ce
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, KFold
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, recall_score, precision_score, f1_score
import xgboost as xgb

get_ipython().run_line_magic('matplotlib', 'inline')
sns.set(style="whitegrid")
warnings.filterwarnings("ignore")
pd.set_option('display.float_format', lambda x: '%.2f' % x)


# In[2]:


dtypes = {
        'MachineIdentifier':                                    'category',
        'AVProductsInstalled':                                  'float16',
        'AVProductsEnabled':                                    'float16',
        'IsProtected':                                          'float16',
        'Census_ProcessorCoreCount':                            'float16',
        'Census_SystemVolumeTotalCapacity':                     'float32',
        'Census_IsAlwaysOnAlwaysConnectedCapable':              'float16',
        'Wdft_IsGamer':                                         'float16',
        'AvSigVersion':                                         'category',
        'OsBuildLab':                                           'category',
        'Census_OSVersion':                                     'category',
        'AppVersion':                                           'category',
        'EngineVersion':                                        'category',
        'Census_PowerPlatformRoleName':                         'category',
        'OsPlatformSubRelease':                                 'category',
        'Census_OSInstallTypeName':                             'category',
        'SkuEdition':                                           'category',
        'Census_ActivationChannel':                             'category',
        'Census_OSWUAutoUpdateOptionsName':                     'category',
        'ProductName':                                          'category',
        'Platform':                                             'category',
        'Census_PrimaryDiskTypeName':                           'category',
        'Census_DeviceFamily':                                  'category',
        'Census_OSArchitecture':                                'category',
        'Processor':                                            'category',
        'HasDetections':                                        'int8'
        }

label = ['HasDetections']

ids = ['MachineIdentifier']

numerical_features = ['AVProductsEnabled', 'AVProductsInstalled', 
                      'Census_ProcessorCoreCount', 'Census_SystemVolumeTotalCapacity']

binary_features = ['Census_IsAlwaysOnAlwaysConnectedCapable', 'IsProtected', 'Wdft_IsGamer']

version_features = ['AvSigVersion', 'OsBuildLab', 'Census_OSVersion', 'AppVersion', 'EngineVersion']

# < 10 categories
low_cardinality_features = ['Census_PowerPlatformRoleName', 'OsPlatformSubRelease', 
                            'Census_OSInstallTypeName', 'SkuEdition', 'Census_ActivationChannel', 
                            'Census_OSWUAutoUpdateOptionsName', 'ProductName', 
                            'Platform', 'Census_PrimaryDiskTypeName', 'Census_DeviceFamily', 
                            'Census_OSArchitecture', 'Processor']

use_columns = numerical_features + binary_features + version_features + low_cardinality_features


# ### Load data
# 
# I reduced the size so it could run on Kaggle, I run it locally with all the data.

# In[3]:


train = pd.read_csv('../input/microsoft-malware-prediction/train.csv', dtype=dtypes, usecols=(use_columns + label), nrows=1000000)
print(train.shape)


# ## Simplification of version related features
# ### Reduce granularity on version features

# In[4]:


for feature in version_features:
    if feature in ['EngineVersion']:
        train[feature] = train[feature].apply(lambda x : ".".join(x.split('.')[:3]))
    elif feature in ['OsBuildLab']:
        train[feature] = train[feature].apply(lambda x : ".".join(x.split('.')[:1]))
    else:
        train[feature] = train[feature].apply(lambda x : ".".join(x.split('.')[:2]))


# In[5]:


# Remove rows with NA
train.dropna(inplace=True)


# ## Encoding
# 
# From analysing a different number of encoders (One hot, Hash, frequency, binary), the one with best results was the Target Encoder.

# In[6]:


Y_train = train[label]
X_train = train.drop(label, axis = 1)

encoder = ce.TargetEncoder(cols=(version_features + low_cardinality_features))
encoder.fit(X_train, Y_train)
X_train = encoder.fit_transform(X_train.reset_index(), Y_train)


# ### Fill missing values with mean
# The values will be filled with the mean value, since it's the base to our encoder.

# In[7]:


X_train.fillna(X_train.mean(), inplace=True)


# ## Adversarial Validation
# When looking at different kinds techniques to avoid overfitting, the one that is most fit to our problems is Adversarial Validation. Which gives us probabilities of a given row from a train dataset to belong to the test dataset.
# 
# * *References: [Improve Your Model Performance using Cross Validation (in Python and R)](https://www.analyticsvidhya.com/blog/2018/05/improve-model-performance-cross-validation-in-python-r/)*

# In[8]:


test = dd.read_csv('../input/microsoft-malware-prediction/test.csv', dtype=dtypes, usecols=(use_columns + ids)).compute()


# In[9]:


test.drop('MachineIdentifier',axis=1, inplace=True)


# In[10]:


for feature in version_features:
    if feature in ['EngineVersion']:
        test[feature] = test[feature].apply(lambda x : ".".join(x.split('.')[:3]))
    elif feature in ['OsBuildLab']:
        test[feature] = test[feature].apply(lambda x : ".".join(x.split('.')[:1]))
    else:
        test[feature] = test[feature].apply(lambda x : ".".join(x.split('.')[:2]))
        
test = encoder.transform(test.reset_index())


# In[11]:


test.drop('index', axis = 1, inplace = True)
X_train.drop('index', axis = 1, inplace = True)
test['is_train'] = 0
X_train['is_train'] = 1


# In[17]:


df = pd.concat([X_train, test], axis = 0)
df.describe()


# In[14]:


df.head()


# In[15]:


X_train.head()


# In[18]:


y = df['is_train']
df.drop('is_train', axis = 1, inplace = True) 

# Xgboost parameters
xgb_params = {'learning_rate': 0.05, 
              'max_depth': 4,
              'subsample': 0.9,        
              'colsample_bytree': 0.9,
              'objective': 'binary:logistic',
              'silent': 1, 
              'n_estimators':100, 
              'gamma':1,         
              'min_child_weight':4}   
clf = xgb.XGBClassifier(**xgb_params, seed = 10)
clf.fit(df, y)


# In[ ]:


del test, Y_train, df, y


# In[20]:


X_train.head()


# In[21]:


X_train.drop('is_train', axis = 1, inplace = True) 

probs = clf.predict_proba(X_train)[:,1]
new_df = pd.DataFrame({'id':X_train.index, 'probs':probs})
new_df = new_df.sort_values(by = 'probs', ascending=False)


# In[36]:


val_set_ids = new_df.iloc[1:np.int(new_df.shape[0]*0.2),1]


# In[38]:


val_set_ids.to_csv('validation_20.csv')


# ### To read

# In[31]:


# # Adversarial validation idexes
# avi = pd.read_csv('../input/validation_20.csv', names=['indexes', 'probability'])

# # Split in train and validation
# X_train = train[~train.index.isin(avi['indexes'])]
# 2X_val = train[train.index.isin(avi['indexes'])]

