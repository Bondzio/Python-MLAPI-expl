#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
import seaborn as sns
pd.options.display.max_columns = 100
import time
import os
print(os.listdir("../input"))
import warnings
warnings.simplefilter('ignore', FutureWarning)


# In[ ]:


get_ipython().run_cell_magic('time', '', "# reading a subset of the data for EDA:\ntrain = pd.read_csv('../input/train.csv', nrows=1000000, low_memory=False)\n\n# Distribution of interest variable in the training dataset:\nsns.countplot(train.HasDetections)")


# We see that the malware are almost equaly distributed so, we should check the interaction of various categorical features with the reposnse variable. This will help us select features for the modeling process. 
# 
# Before working on the interactions lets get a quick overview of the data based:

# ** Process **
# * Step 1:  Summarize and understand the data:
#     * We subset the data into numeric only and categorical only and then describe them because if we use the [DOT] describe() on entire dataseet we will get a summary of the numeric only columns.
# * Step 2: Find Constant columns and remove them
#     * Remove them since there is no variance.
# * Step 3: Generate interactions

# In[ ]:


# Create a list of Numerical columns and Generate a summary of the data.
numeric_columns = train._get_numeric_data().columns
train[numeric_columns].describe().T


# In[ ]:


# What proportion of the data is missing:
(train[numeric_columns].isnull().sum().sort_values(ascending = False)[:43]/train.shape[0])[:37]


# In[ ]:


# Create a list of Categorical columns and Generate a summary of the data.
categorical_columns = train[train.columns[~train.columns.isin(numeric_columns)]].columns
train[categorical_columns].describe().T


# In[ ]:


# Percentage of missing data in Categorical Columns
(train[categorical_columns].isnull().sum().sort_values(ascending = False)[:43]/train.shape[0])[:9]


# In[ ]:


# Step 2:

# Getting list of columns with a constant value (This will be dropped later)
drop_these_columns = [c for c in train.columns if train[c].nunique(dropna=False)==1 ]
drop_these_columns


# ** All columns have more than 1 unique value!
# 
# * A column is considered constant if it has a repeatable value and no missing value.

# In[ ]:


# Step 3:

def plot_variables(var1, var2, arr=(16,6)):
    plt.figure(figsize=arr)
    plt.subplot(1, 2, 1)
    sns.countplot(train[var1])
    plt.xticks(rotation=45)
    plt.subplot(1, 2, 2)
    sns.barplot(train[var1], train[var2])
    plt.xticks(rotation=90)
    plt.tight_layout()
    plt.show()
#     print(pd.crosstab(train[var1], train[var2]).T)

# Get understanding of the distribution and interaction of various features with the response variable:
for i in categorical_columns:
    if train[i].nunique() < 15:  # limited to 15 so that the chart remains understandable
        print(i)
        plot_variables(i, "HasDetections")


# # Data Engineering and Model Building
# 
# Will be uploaded asap!
