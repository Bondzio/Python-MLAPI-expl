#!/usr/bin/env python
# coding: utf-8

# # Convolutional Neural Network for Malware Revealer + Ensembling

# In this notebook we trained three convolutonal neural networks based on 'SqueezeNet1_1' to classify our dataset of malwares/benign files, the training was done on different subset of the data to use ensembling technics later.
# 
# This training part was done after preprocessing the executables, it consisted of transforming the binaries to images. You can find out more about this in our [github project](https://github.com/youben11/malware-revealer).

# ## Load the necessary libraries 

# In[ ]:


import os
import torch
import torch.optim as optim
from torchvision import transforms, models
import torchvision 
from collections import OrderedDict
from torch import nn 
import matplotlib.pyplot as plt
import numpy as np


# ## Load the dataset

# In[ ]:


datasets_dir = "../input/malwarerevealer3subsetimages/malware-revealer-3subset-images/"
data1 = datasets_dir + "data1"
data2 = datasets_dir + "data2"
data3 = datasets_dir + "data3"
datasets = ["data1", "data2", "data3"]
data_path = {
    'data1': data1,
    'data2': data2,
    'data3': data3,
}


# In[ ]:


data_transforms = transforms.Compose([
    transforms.Resize(224),              
    transforms.ToTensor(),
])

image_datasets = {
    name: torchvision.datasets.ImageFolder(data_path[name], transform=data_transforms) for name in datasets
}


# ## Split the dataset into training, validation and test set
# A good practice is to split the dataset into : 
# - Training set : the weights of our neural network will be trained on this set of training examples and it will be the larger portion of the data set 70% .
# - Validation set : to measure the progress of the training and be able to tune the hyper parameters more effectively and watch out the the training progress in order to detect any underfitting or overfitting behaviours , it will be about 20% of our original data set .
# - The test set : this one will remain untouchable and will not be involved in any training ,and it's used to purely test the performance of the trained model , the size will be 10% from our original data set.

# In[ ]:


from torch.utils.data.sampler import SubsetRandomSampler
from sklearn.model_selection import train_test_split
from torch.utils.data.sampler import SubsetRandomSampler
valid_size_and_test = 0.3

targets = {name: image_datasets[name].targets for name in datasets}

dataloaders = {}
for name in datasets:
    train_idx, rest_idx= train_test_split(np.arange(len(targets[name])), test_size=valid_size_and_test, random_state=42, shuffle=True, stratify=targets[name])
    test_size = int(len(rest_idx) * valid_size_and_test)
    valid_idx, test_idx = rest_idx[:test_size], rest_idx[test_size:]
    
    dataloaders[name] = {
        'trainLoader' : torch.utils.data.DataLoader(image_datasets[name], batch_size=32,sampler=SubsetRandomSampler(train_idx)),
        'validLoader' : torch.utils.data.DataLoader(image_datasets[name], batch_size=32,sampler=SubsetRandomSampler(valid_idx)),
        'testLoader' :  torch.utils.data.DataLoader(image_datasets[name], batch_size=32,sampler=SubsetRandomSampler(test_idx)),
    }


# ## Instanciating a pretrained Squeezenet1_1

# We need to adjust the final layer so it just output 2 classes

# In[ ]:


def new_squeezenet1_1(device):
    model = models.squeezenet1_1(pretrained=True)
    # Customizing the squeezenet architecture
    features = list(model.classifier.children())
    features[1] = nn.Conv2d(model.classifier[1].in_channels, 2, kernel_size=(1,1))
    model.classifier = nn.Sequential(*features)
    model.num_classes = 2
    # make sure gradient is calcualted
    for param in model.parameters():
        param.requires_grad = True
    model.to(device)
    
    return model

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model = new_squeezenet1_1(device)
print(model.classifier[1].in_channels)
print( model.classifier[1].out_channels)


# ## Define the hyper parameters

# In[ ]:


epochs = 90
steps = 0
running_loss = 0
print_every = 26


# ## Train the 3 models

# In[ ]:


training_losses = {}
validation_losses = {}
for name in dataloaders.keys():
    dataloader = dataloaders[name]
    model = new_squeezenet1_1(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adadelta(model.parameters(), lr=0.002)
    
    min_val_loss = np.inf
    training_loss = []
    validation_loss = []
    for e in range(epochs):
        running_loss = 0
        model.train() 

        for ii, (inputs, labels) in enumerate(dataloader['trainLoader']):
            steps += 1
            #move the labels and inputs to the device ( GPU or CPU )
            inputs,labels = inputs.to(device), labels.to(device)
            # get rid of accumulated gradient 
            optimizer.zero_grad()

            # Forward and backward passes
            outputs = model.forward(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            # cumulating the loss 
            running_loss += loss.item()

            if steps % print_every == 0:
                model.eval()
                vlost = 0
                accuracy=0
                # no grad because we are looping in the validation set we don't need to update the weights ( this data is not used for training the model )
                with torch.no_grad():
                    for ii, (inputs2,labels2) in enumerate(dataloader['validLoader']):

                        optimizer.zero_grad()
                        inputs2, labels2 = inputs2.to(device) , labels2.to(device)
                        model.to(device)
                        with torch.no_grad():    
                            outputs = model.forward(inputs2)
                            vlost = criterion(outputs,labels2)
                            ps = torch.exp(outputs).data
                            equality = (labels2.data == ps.max(1)[1])
                            accuracy += equality.type_as(torch.FloatTensor()).mean()

                    vlost = vlost / len(dataloader['validLoader'])
                    accuracy = accuracy /len(dataloader['validLoader'])
                    #print some statistics 
                    training_loss.append(running_loss/print_every)
                    validation_loss.append(vlost)
                    print("Epoch: {}/{}... ".format(e+1, epochs),
                          "Training Loss: {:.4f} | ".format(running_loss/print_every),
                          "Validation Lost {:.4f} | ".format(vlost),
                           "Accuracy: {:.4f}".format(accuracy))
                    # checkpointing the best model
                    if vlost < min_val_loss:
                        print("New validation loss, checkpointing ...")
                        min_val_loss = vlost
                        torch.save(model.state_dict(), 'squeezenet1_1_%s.pth' % name)
                        
            running_loss = 0
    
    # saving losses for analyzing training behaviour
    training_losses[name] = training_loss
    validation_losses[name] = validation_loss

print("\nTraining process finished ")
 


# ## Plot some statistics about the trainings bahaviour
# This section will help in tracking the training behaviour because ploting the data makes it so easy to see the trends and get sense about the overall trend to make decision about the next step in order to enhance the performance of the network .

# In[ ]:


for name in training_losses.keys():
    training_loss = training_losses[name]
    validation_loss = validation_losses[name]
    x = [i for i in range(len(validation_loss))]
    plt.plot(x, training_loss)
    plt.plot(x, validation_loss)
    plt.legend(['training loss %s' % name, 'validation loss %s' % name], loc='upper left')
    plt.show()


# ## Tests the 3 models
# It's mendatory to test the model on whole unseen sub set of the data to judge its performance .

# In[ ]:


def load_checkpointed_model(checkpoint_file):
    if checkpoint_file == None:
        return new_squeezenet1_1(device)
    
    model = new_squeezenet1_1(device)
    state_dict = torch.load(checkpoint_file, map_location=device)
    model.load_state_dict(state_dict)
    model.eval()
    return model


def get_overall_accuracy(model, testloader):
    correct = 0
    total = 0
    total_per_label = {0: 0, 1: 0}
    correct_per_label = {0: 0, 1: 0}
    model.to(device)
    with torch.no_grad():
        for data in testloader:
            images, labels = data
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            
            zero_indices = (labels == 0).cpu()
            one_indices = (labels == 1).cpu()
            total_per_label[0] += np.count_nonzero(zero_indices)
            total_per_label[1] += np.count_nonzero(one_indices)
            correct_per_label[0] += np.count_nonzero(labels[zero_indices].cpu() == predicted[zero_indices].cpu())
            correct_per_label[1] += np.count_nonzero(labels[one_indices].cpu() == predicted[one_indices].cpu())

    print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))
    print("Benings {correct}/{total}".format(correct=correct_per_label[0], total=total_per_label[0]))
    print("Malwares {correct}/{total}".format(correct=correct_per_label[1], total=total_per_label[1]))
    
    
for name in datasets:
    checkpoint_file = "squeezenet1_1_%s.pth" % name
    model = load_checkpointed_model(checkpoint_file)
    print("Testing model trained on data: %s" % name)
    get_overall_accuracy(model, dataloaders[name]['testLoader'])


# # Ensembling

# In this section, we are gonna make use of the 3 last trained model to make predictions and aggregate their result

# ## Ensemble model

# In[ ]:



class MalwareRevealerEnsemble(nn.Module):
    
    def __init__(self, model_checkpoints):
        super(MalwareRevealerEnsemble, self).__init__()
        self.models = [load_checkpointed_model(model_checkpoint) for model_checkpoint in model_checkpoints]
        
        
    def forward(self, x):
        preds = [model(x) for model in self.models]
        votes = preds[0]
        for pred in preds[1:]:
            votes += pred
        votes /= len(preds)
        return votes
        


# In[ ]:


# Instanciate an ensemble of 3 models
ensemble = MalwareRevealerEnsemble(["squeezenet1_1_%s.pth" % name for name in datasets])


# ## Evaluating the ensemble model against individual models

# In[ ]:


valid_dir = "../input/malware-test/malware_revealer_test_malwares/data_test"

valid_image_datasets = torchvision.datasets.ImageFolder(valid_dir, transform=data_transforms)
valid_image_loader = torch.utils.data.DataLoader(valid_image_datasets, batch_size=32)


# In[ ]:


print("Ensemble accuracy ...")
get_overall_accuracy(ensemble, valid_image_loader)


# In[ ]:


print("Individual models accuracy ...")
for name in datasets:
    checkpoint_file = "squeezenet1_1_%s.pth" % name
    model = load_checkpointed_model(checkpoint_file)
    print("Testing model trained on data: %s" % name)
    get_overall_accuracy(model, valid_image_loader)

